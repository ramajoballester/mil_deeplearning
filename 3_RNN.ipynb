{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOQcXhYSDjljLcJv8Mc6ERq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramajoballester/mil_deeplearning/blob/main/3_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sesión 3. Redes Neuronales Recurrentes"
      ],
      "metadata": {
        "id": "cmntFP3zjPue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ij_iq60KrD9W"
      },
      "outputs": [],
      "source": [
        "! pip install -q torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "6b732543-395a-4264-aa9d-96130e22ef37"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "import torchmetrics\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e8e20f24-5869-4f5b-80bd-8dabdf2d03c0"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "382b9437-b6c1-4002-bed7-4a37211c02ae"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    # Archivo demasiado grande (probablemente no entre en RAM)\n",
        "    reader =  csv.reader(open(\"alvaro/data/sentiment140/training.1600000.processed.noemoticon.csv\", \"rt\", encoding=\"latin-1\"))\n",
        "    # reader =  csv.reader(open(\"data/sentiment140/training.1600000.processed.noemoticon.csv\", \"rt\", encoding=\"latin-1\"))\n",
        "    data = []\n",
        "    for each_line in reader:\n",
        "        data.append((each_line[-1], int(each_line[0] == '4')))\n",
        "        \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9abf4403-eae6-4cc8-a36b-73032b610792"
      },
      "outputs": [],
      "source": [
        "# data es una lista de tuplas (tweet [str], valor [int])\n",
        "data = get_data()\n",
        "# El tokenizador separa las oraciones en secuencias de palabras\n",
        "tokenizer = torchtext.data.get_tokenizer('basic_english')\n",
        "# Convertir a minúsculas y eliminar marcas de puntuación\n",
        "data_list = [(' '.join(token for token in tokenizer(each[0].lower()) \\\n",
        "                       if token not in punctuation), each[1]) for each in data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8998cbb7-fad2-4a82-b6a7-07548e8e9901",
        "outputId": "797603a2-026a-4abf-db70-bda5eb536cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAV6klEQVR4nO3df4xd5Z3f8fdnbeLQJCb8MMi1ndop7raAGhJGrqtUUVrvLk5SrakE3VmpxaosuUJsm0ituqYrtdk/LEGlLi1qQXWXFEPTgMsuwtosu+uajVaVWDtDQgKGuEwCC65d2wmEOK1g1+y3f9xnkuvhzsyd8XjuHc/7JR2dc7/3PGe+54jxd57nOeeQqkKSpJ8ZdAKSpOFgQZAkARYESVJjQZAkARYESVKzfNAJzNVVV11V69evH3QakrSoPPvss9+vqlW9vlu0BWH9+vWMjY0NOg1JWlSS/MlU3zlkJEkC+igISX42yXNdy4+SfCHJFUkOJHm5rS/vanNXkvEkR5Pc3BW/Kcnz7bv7kqTFVyR5rMUPJVl/IU5WkjS1GQtCVR2tqhur6kbgJuD/AU8Au4CDVbURONg+k+Q6YBS4HtgK3J9kWTvcA8BOYGNbtrb4DuDNqroWuBe4Z35OT5LUr9kOGW0BvltVfwJsA/a2+F7glra9DXi0qt6pqleAcWBTktXAyqp6pjrvy3h4UpuJYz0ObJnoPUiSFsZsC8Io8JW2fU1VnQBo66tbfA3welebYy22pm1Pjp/TpqrOAm8BV84yN0nSeei7ICR5H/CLwH+fadcesZomPl2byTnsTDKWZOz06dMzpCFJmo3Z9BA+A3yjqk62zyfbMBBtfarFjwHrutqtBY63+Noe8XPaJFkOXAa8MTmBqtpTVSNVNbJqVc/baCVJczSbgvDL/HS4CGA/sL1tbwee7IqPtjuHNtCZPD7chpXOJNnc5gdun9Rm4li3Ak+X7+WWpAXV14NpSf4C8PPAP+4K3w3sS7IDeA24DaCqjiTZB7wInAXurKp3W5s7gIeAS4Gn2gLwIPBIknE6PYPR8zgnSdIcZLH+IT4yMlKL8Unl9bu+2jP+6t2fW+BMJC1FSZ6tqpFe3/mksiQJsCBIkhoLgiQJWMRvO72Ydc8zOLcgaaHYQ5AkARYESVJjQZAkARYESVJjQZAkAd5ldMF4p5CkxcYegiQJsIcw9OxpSFoo9hAkSYAFQZLUWBAkSYAFQZLUWBAkSYB3GS0q3nEk6UKyhyBJAiwIkqTGgiBJApxDmFfdY/yStNj01UNI8uEkjyf5TpKXkvzNJFckOZDk5ba+vGv/u5KMJzma5Oau+E1Jnm/f3ZckLb4iyWMtfijJ+vk+UUnS9PodMvr3wO9V1V8FPga8BOwCDlbVRuBg+0yS64BR4HpgK3B/kmXtOA8AO4GNbdna4juAN6vqWuBe4J7zPC9J0izNWBCSrAQ+BTwIUFV/WlU/BLYBe9tue4Fb2vY24NGqeqeqXgHGgU1JVgMrq+qZqirg4UltJo71OLBlovcgSVoY/fQQPgqcBv5Lkm8m+c0kHwCuqaoTAG19ddt/DfB6V/tjLbambU+On9Omqs4CbwFXTk4kyc4kY0nGTp8+3ecpSpL60U9BWA58Anigqj4O/F/a8NAUev1lX9PEp2tzbqBqT1WNVNXIqlWrps9akjQr/RSEY8CxqjrUPj9Op0CcbMNAtPWprv3XdbVfCxxv8bU94ue0SbIcuAx4Y7YnI0mauxkLQlX9H+D1JD/bQluAF4H9wPYW2w482bb3A6PtzqENdCaPD7dhpTNJNrf5gdsntZk41q3A022eQZK0QPp9DuGfAF9O8j7ge8A/olNM9iXZAbwG3AZQVUeS7KNTNM4Cd1bVu+04dwAPAZcCT7UFOhPWjyQZp9MzGD3P85IkzVJfBaGqngNGeny1ZYr9dwO7e8THgBt6xN+mFRTNni+9kzQffHWFJAmwIEiSGguCJAnw5XYaQs6JSINhD0GSBFgQJEmNBUGSBFgQJEmNBUGSBHiX0UXHO3QkzZU9BEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUWBEkS0Oe7jJK8CpwB3gXOVtVIkiuAx4D1wKvA36+qN9v+dwE72v7/tKp+v8VvAh4CLgV+F/h8VVWSFcDDwE3AD4BfqqpX5+UML4AL8b6g7mNK0iDMpofwt6vqxqoaaZ93AQeraiNwsH0myXXAKHA9sBW4P8my1uYBYCewsS1bW3wH8GZVXQvcC9wz91NSL+t3ffUniyT1cj5DRtuAvW17L3BLV/zRqnqnql4BxoFNSVYDK6vqmaoqOj2CW3oc63FgS5KcR26SpFnq9/XXBfxBkgL+U1XtAa6pqhMAVXUiydVt3zXAH3e1PdZif9a2J8cn2rzejnU2yVvAlcD3u5NIspNOD4OPfOQjfaY+eP5VLmkx6LcgfLKqjrd/9A8k+c40+/b6y76miU/X5txApxDtARgZGXnP95KkuetryKiqjrf1KeAJYBNwsg0D0dan2u7HgHVdzdcCx1t8bY/4OW2SLAcuA96Y/elIkuZqxoKQ5ANJPjSxDfwC8AKwH9jedtsOPNm29wOjSVYk2UBn8vhwG146k2Rzmx+4fVKbiWPdCjzd5hkkSQuknyGja4An2hzvcuC/VdXvJfk6sC/JDuA14DaAqjqSZB/wInAWuLOq3m3HuoOf3nb6VFsAHgQeSTJOp2cwOg/nJkmahRkLQlV9D/hYj/gPgC1TtNkN7O4RHwNu6BF/m1ZQJEmD4ZPKkiSg/7uMdBG5EE9aS1r87CFIkgALgiSpsSBIkgDnEDQkfL2HNHj2ECRJgAVBktRYECRJgHMIi5Zj7pLmmz0ESRJgD0FdfIJZWtrsIUiSAAuCJKmxIEiSAOcQzpt3+0i6WNhDkCQBFgRJUuOQkXryFlRp6bGHIEkCLAiSpKbvgpBkWZJvJvmd9vmKJAeSvNzWl3fte1eS8SRHk9zcFb8pyfPtu/uSpMVXJHmsxQ8lWT9/pyhJ6sds5hA+D7wErGyfdwEHq+ruJLva519Nch0wClwP/EXgfyT5K1X1LvAAsBP4Y+B3ga3AU8AO4M2qujbJKHAP8EvnfXbzxFtLJS0FffUQkqwFPgf8Zld4G7C3be8FbumKP1pV71TVK8A4sCnJamBlVT1TVQU8PKnNxLEeB7ZM9B4kSQuj3yGjfwf8C+DPu2LXVNUJgLa+usXXAK937Xesxda07cnxc9pU1VngLeDKyUkk2ZlkLMnY6dOn+0xdktSPGYeMkvxd4FRVPZvk030cs9df9jVNfLo25waq9gB7AEZGRt7zvS48b0eVLl79zCF8EvjFJJ8F3g+sTPJfgZNJVlfViTYcdKrtfwxY19V+LXC8xdf2iHe3OZZkOXAZ8MYcz0nNxTD3YQGSFs6MQ0ZVdVdVra2q9XQmi5+uqn8A7Ae2t922A0+27f3AaLtzaAOwETjchpXOJNnc5gdun9Rm4li3tp9hD0CSFtD5PKl8N7AvyQ7gNeA2gKo6kmQf8CJwFriz3WEEcAfwEHApnbuLnmrxB4FHkozT6RmMnkdekqQ5mFVBqKqvAV9r2z8Atkyx325gd4/4GHBDj/jbtIIiSRoMn1SWJAG+3E7nYfKkdT+Tvk4SS8PLHoIkCbAgSJIah4w0b6YaDroYnoeQlgJ7CJIkwIIgSWosCJIkwIIgSWosCJIkwIIgSWq87XSJ85ZQSRPsIUiSAAuCJKmxIEiSAAuCJKmxIEiSAAuCJKmxIEiSAAuCJKmxIEiSgD4KQpL3Jzmc5FtJjiT59Ra/IsmBJC+39eVdbe5KMp7kaJKbu+I3JXm+fXdfkrT4iiSPtfihJOvn/1QlSdPpp4fwDvB3qupjwI3A1iSbgV3AwaraCBxsn0lyHTAKXA9sBe5Psqwd6wFgJ7CxLVtbfAfwZlVdC9wL3DMP5yZJmoUZ32VUVQX8uH28pC0FbAM+3eJ7ga8Bv9rij1bVO8ArScaBTUleBVZW1TMASR4GbgGeam2+2I71OPAfkqT9bA2Y7zuSloa+5hCSLEvyHHAKOFBVh4BrquoEQFtf3XZfA7ze1fxYi61p25Pj57SpqrPAW8CVPfLYmWQsydjp06f7O0NJUl/6ettpVb0L3Jjkw8ATSW6YZvf0OsQ08enaTM5jD7AHYGRkxN7DImfPQxous7rLqKp+SGdoaCtwMslqgLY+1XY7BqzrarYWON7ia3vEz2mTZDlwGfDGbHKTJJ2ffu4yWtV6BiS5FPg54DvAfmB722078GTb3g+MtjuHNtCZPD7chpXOJNnc7i66fVKbiWPdCjzt/IEkLax+hoxWA3vbnUI/A+yrqt9J8gywL8kO4DXgNoCqOpJkH/AicBa4sw05AdwBPARcSmcy+akWfxB4pE1Av0HnLiVJ0gLq5y6jbwMf7xH/AbBlija7gd094mPAe+YfquptWkGRJA2GTypLkgALgiSpsSBIkgALgiSp6evBNGm2fOhMWnzsIUiSAAuCJKmxIEiSAAuCJKmxIEiSAAuCJKmxIEiSAAuCJKmxIEiSAAuCJKmxIEiSAAuCJKmxIEiSAAuCJKnx9ddT8PXNkpYaewiSJKCPgpBkXZI/TPJSkiNJPt/iVyQ5kOTltr68q81dScaTHE1yc1f8piTPt+/uS5IWX5HksRY/lGT9/J+qJGk6/fQQzgL/rKr+GrAZuDPJdcAu4GBVbQQOts+070aB64GtwP1JlrVjPQDsBDa2ZWuL7wDerKprgXuBe+bh3CRJszBjQaiqE1X1jbZ9BngJWANsA/a23fYCt7TtbcCjVfVOVb0CjAObkqwGVlbVM1VVwMOT2kwc63Fgy0TvQZK0MGY1h9CGcj4OHAKuqaoT0CkawNVttzXA613NjrXYmrY9OX5Om6o6C7wFXNnj5+9MMpZk7PTp07NJXZI0g74LQpIPAr8FfKGqfjTdrj1iNU18ujbnBqr2VNVIVY2sWrVqppQlSbPQV0FIcgmdYvDlqvrtFj7ZhoFo61MtfgxY19V8LXC8xdf2iJ/TJsly4DLgjdmejCRp7vq5yyjAg8BLVfUbXV/tB7a37e3Ak13x0Xbn0AY6k8eH27DSmSSb2zFvn9Rm4li3Ak+3eQZJ0gLp58G0TwL/EHg+yXMt9i+Bu4F9SXYArwG3AVTVkST7gBfp3KF0Z1W929rdATwEXAo81RboFJxHkozT6RmMnud56SLU/bDgq3d/boCZSBenGQtCVf1Peo/xA2yZos1uYHeP+BhwQ4/427SCIkkaDJ9UliQBFgRJUuPL7br4QjtJS5k9BEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDUzFoQkX0pyKskLXbErkhxI8nJbX9713V1JxpMcTXJzV/ymJM+37+5LkhZfkeSxFj+UZP38nqIkqR/99BAeArZOiu0CDlbVRuBg+0yS64BR4PrW5v4ky1qbB4CdwMa2TBxzB/BmVV0L3AvcM9eTkSTN3YwFoar+CHhjUngbsLdt7wVu6Yo/WlXvVNUrwDiwKclqYGVVPVNVBTw8qc3EsR4Htkz0HiRJC2eucwjXVNUJgLa+usXXAK937Xesxda07cnxc9pU1VngLeDKOeYlSZqj+Z5U7vWXfU0Tn67New+e7EwylmTs9OnTc0xRktTLXAvCyTYMRFufavFjwLqu/dYCx1t8bY/4OW2SLAcu471DVABU1Z6qGqmqkVWrVs0xdUlSL3MtCPuB7W17O/BkV3y03Tm0gc7k8eE2rHQmyeY2P3D7pDYTx7oVeLrNM0iSFtDymXZI8hXg08BVSY4B/xq4G9iXZAfwGnAbQFUdSbIPeBE4C9xZVe+2Q91B546lS4Gn2gLwIPBIknE6PYPReTkzSdKszFgQquqXp/hqyxT77wZ294iPATf0iL9NKyiSpMHxSWVJEmBBkCQ1FgRJEmBBkCQ1FgRJEmBBkCQ1M952erFbv+urg05BkoaCPQRJEmBBkCQ1FgRJEmBBkCQ1S35SWYtT980Ar979uQFmIl087CFIkgALgiSpsSBIkgALgiSpsSBIkgALgiSpsSBIkgALgiSp8cE0LXo+pCbND3sIkiRgiApCkq1JjiYZT7Jr0PlI0lIzFENGSZYB/xH4eeAY8PUk+6vqxcFmpsXG4SNp7oaiIACbgPGq+h5AkkeBbcAFKQj+X9KWBouDNDvDUhDWAK93fT4G/I3JOyXZCexsH3+c5OgcftZVwPfn0G4hmeP8+EmOuWfAmUxvUV3LIWaO/flLU30xLAUhPWL1nkDVHmDPef2gZKyqRs7nGBeaOc6PxZAjLI48zXF+DHuOwzKpfAxY1/V5LXB8QLlI0pI0LAXh68DGJBuSvA8YBfYPOCdJWlKGYsioqs4m+RXg94FlwJeq6sgF+nHnNeS0QMxxfiyGHGFx5GmO82Ooc0zVe4bqJUlL0LAMGUmSBsyCIEkCllBBGNZXYyR5NcnzSZ5LMtZiVyQ5kOTltr58AHl9KcmpJC90xabMK8ld7doeTXLzAHP8YpL/3a7nc0k+O+Ac1yX5wyQvJTmS5PMtPjTXcpoch+ZaJnl/ksNJvtVy/PUWH5rrOEOeQ3Mtp1VVF/1CZ6L6u8BHgfcB3wKuG3ReLbdXgasmxf4NsKtt7wLuGUBenwI+AbwwU17Ade2argA2tGu9bEA5fhH45z32HVSOq4FPtO0PAf+r5TI013KaHIfmWtJ5VumDbfsS4BCweZiu4wx5Ds21nG5ZKj2En7wao6r+FJh4Ncaw2gbsbdt7gVsWOoGq+iPgjUnhqfLaBjxaVe9U1SvAOJ1rPogcpzKoHE9U1Tfa9hngJTpP5g/NtZwmx6kMIseqqh+3j5e0pRii6zhDnlMZSJ5TWSoFoderMab7D34hFfAHSZ5tr+YAuKaqTkDnlxW4emDZnWuqvIbt+v5Kkm+3IaWJIYSB55hkPfBxOn81DuW1nJQjDNG1TLIsyXPAKeBAVQ3ldZwiTxiiazmVpVIQ+no1xoB8sqo+AXwGuDPJpwad0BwM0/V9APjLwI3ACeDftvhAc0zyQeC3gC9U1Y+m27VHbEHy7JHjUF3Lqnq3qm6k8yaDTUlumGb3gV3HKfIcqms5laVSEIb21RhVdbytTwFP0OkunkyyGqCtTw0uw3NMldfQXN+qOtl+If8c+M/8tPs9sByTXELnH9ovV9Vvt/BQXcteOQ7jtWx5/RD4GrCVIbuO3brzHNZrOdlSKQhD+WqMJB9I8qGJbeAXgBfo5La97bYdeHIwGb7HVHntB0aTrEiyAdgIHB5AfhP/KEz4e3SuJwwoxyQBHgReqqrf6PpqaK7lVDkO07VMsirJh9v2pcDPAd9hiK7jdHkO07Wc1qBmsxd6AT5L5+6J7wK/Nuh8Wk4fpXOHwbeAIxN5AVcCB4GX2/qKAeT2FTpd2z+j81fMjunyAn6tXdujwGcGmOMjwPPAt+n8sq0ecI5/i84QwLeB59ry2WG6ltPkODTXEvjrwDdbLi8A/6rFh+Y6zpDn0FzL6RZfXSFJApbOkJEkaQYWBEkSYEGQJDUWBEkSYEGQJDUWBEkSYEGQJDX/H4RngzW1w+yPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Histogram por longitud de tweet\n",
        "x = [len(each[0]) for each in data_list]\n",
        "plot = plt.hist(x, bins=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(torch.Tensor(x) > 140).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHLUeE2kBHqm",
        "outputId": "71a7be67-2f22-4b49-b007-d63a05aeff06"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4777)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "11fe1ac5-a650-4f2c-ba2a-34c3a31b5195"
      },
      "outputs": [],
      "source": [
        "# Cargamos la herramienta GloVe para crear los embeddings de las palabras\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6d3313bb-b39a-40b7-b862-14f4d5e1082b"
      },
      "outputs": [],
      "source": [
        "# Minimum frequency to appear in vocab\n",
        "min_freq = 10\n",
        "# Counter counts word repetitions\n",
        "counter = Counter()\n",
        "# specials = ['<unk>', '<BOS>', '<EOS>', '<PAD>']\n",
        "specials = ['<unk>', '<PAD>']\n",
        "for each in specials:\n",
        "    counter.update([each])\n",
        "    counter[each] = min_freq\n",
        "for (line, label) in data_list:\n",
        "    counter.update(tokenizer(line))\n",
        "vocab = torchtext.vocab.vocab(dict(counter), min_freq=10)\n",
        "# Set index for OOV (Out Of Vocabulary) token occurs\n",
        "vocab.set_default_index(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "460499ed-c3a7-40bd-9173-3e04db6e6e74"
      },
      "outputs": [],
      "source": [
        "# Transform words into ints\n",
        "text_transform = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "data_preprocessed = [(torch.tensor(text_transform(each[0])),\n",
        "                      torch.tensor(each[1])) \\\n",
        "                     for each in data_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a7a20b51-467f-4072-a60a-f136f71d4c7a",
        "outputId": "5a492d29-aeff-47bf-b475-ec536efa7eed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Cannot actually keep my eyes open.., I feel like shit ', 0)\n",
            "('cannot actually keep my eyes open i feel like shit', 0)\n",
            "(tensor([2510,  606,  809,   55,  239, 1529,   42,  285,   60,  981]), tensor(0))\n"
          ]
        }
      ],
      "source": [
        "# Original\n",
        "print(data[80000])\n",
        "# Normalized text\n",
        "print(data_list[80000])\n",
        "# Tokenized text (int)\n",
        "print(data_preprocessed[80000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cfd0d134-41d2-4b7e-91c7-078ecc066abc"
      },
      "outputs": [],
      "source": [
        "random.seed(8080)\n",
        "random.shuffle(data_preprocessed)\n",
        "data_length = len(data_preprocessed)\n",
        "train_list, test_list = torch.utils.data.random_split(data_preprocessed, \n",
        "                              [int(data_length*0.75),\n",
        "                              int(data_length*0.25)], \n",
        "                              generator=torch.manual_seed(4040))\n",
        "# train_list, test_list, _ = torch.utils.data.random_split(data_preprocessed, \n",
        "#                               [10000, 5000, int(len(data_preprocessed)-15000)], \n",
        "#                               generator=torch.manual_seed(4040))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "39eded92-12cd-483f-a525-626fc6eff868"
      },
      "outputs": [],
      "source": [
        "input_size = 50\n",
        "hidden_size = 60\n",
        "n_classes = 1\n",
        "batch_size = 1024\n",
        "lr = 0.001\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes Neuronales Recurrentes (RNN)"
      ],
      "metadata": {
        "id": "yc9bhC82jByA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "a1868abd-96b1-4c72-afbc-e136e0ee0889"
      },
      "outputs": [],
      "source": [
        "# Sigmoid is no longer needed if loss=BCEWithLogitsLoss\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        # self.emb = nn.Embedding.from_pretrained(glove.vectors, freeze=False)\n",
        "        self.emb = nn.Embedding(400000, 50)\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Look up the embedding\n",
        "        x = self.emb(x)\n",
        "        print(x.shape)\n",
        "        # Forward propagate the RNN\n",
        "        out, last_hidden = self.rnn(x)\n",
        "        # Pass the output of the last time step to the classifier\n",
        "        out = self.fc(out[:, -1, :])\n",
        "#         out = self.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "a97838ed-6f96-4135-8e1c-fb6679b39fd4"
      },
      "outputs": [],
      "source": [
        "# Pad sentences from batch to the longest sentence \n",
        "def collate_batch(batch):\n",
        "    x, y = map(list, zip(*batch))\n",
        "    return torch.nn.utils.rnn.pad_sequence(x, padding_value=3, batch_first=True), torch.tensor(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "14b28fdd-77b0-4e45-a864-1aba742d46ad"
      },
      "outputs": [],
      "source": [
        "# Sample batch indices from pool of similar lengths\n",
        "def batch_sampler(data_list):\n",
        "    indices = [(i, len(s[0])) for i, s in enumerate(data_list)]\n",
        "    random.shuffle(indices)\n",
        "    pooled_indices = []\n",
        "    # create pool of batch_size*100 indices with similar lengths \n",
        "    for i in range(0, len(indices), batch_size * 100):\n",
        "        pooled_indices.extend(sorted(indices[i:i + batch_size * 100], key=lambda x: x[1]))\n",
        "\n",
        "    pooled_indices = [x[0] for x in pooled_indices]\n",
        "\n",
        "    # yield indices for current batch\n",
        "    for i in range(0, len(pooled_indices), batch_size):\n",
        "        yield pooled_indices[i:i + batch_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "f2af40ce-599e-468b-8507-82fc6c0be8d4"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_list, collate_fn=collate_batch,\n",
        "                                               batch_sampler=batch_sampler(train_list))\n",
        "test_dataloader = torch.utils.data.DataLoader(test_list, collate_fn=collate_batch,\n",
        "                                              batch_sampler=batch_sampler(test_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "54dc5bde-abd1-49e7-8fb6-dbc8169958c1"
      },
      "outputs": [],
      "source": [
        "model = RNN(input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_classes=n_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "1d4d5c2b-715b-4efc-a78d-ee435fa13c39"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
        "# loss_fn = nn.BCELoss().to(device)\n",
        "metrics_fn = torchmetrics.Accuracy().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(model.parameters()).is_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S43_uQsQFaYN",
        "outputId": "c6722dca-7d9f-41f9-c453-3e98ddce691d"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "c09ef347-ab00-4118-9330-1b37a46920a1"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, device, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(x)\n",
        "        loss = loss_fn(preds.squeeze(1), y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "ec4723c8-27a3-4a48-a425-07e28ac35089"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader, device, loss_fn, metrics_fn=None):\n",
        "    loss_total = 0.0\n",
        "    model.eval()\n",
        "    metrics_fn.reset()\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            preds = model(x)\n",
        "            loss = loss_fn(preds.squeeze(1), y.float())\n",
        "            metrics = metrics_fn(torch.sigmoid(preds.squeeze(1)), y)\n",
        "            loss_total += loss\n",
        "        metrics = metrics_fn.compute()\n",
        "        return loss_total, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": [],
        "id": "5753c85f-d849-4299-beb2-3fde31b9d811",
        "outputId": "8fc14dac-49aa-4a43-e502-5ccb35bc269b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training Loss: 557.2955, Training Accuracy: 78.74%\n",
            "Test Loss: 188.1170, Test Accuracy: 78.14%\n",
            "Time elapsed - Training: 10.60, test train: 5.94, test test: 1.94\n",
            "\n",
            "Epoch 2\n",
            "Training Loss: 520.9472, Training Accuracy: 80.41%\n",
            "Test Loss: 178.1470, Test Accuracy: 79.44%\n",
            "Time elapsed - Training: 10.57, test train: 5.92, test test: 1.92\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_list, batch_sampler\u001b[38;5;241m=\u001b[39mbatch_sampler(train_list),\n\u001b[1;32m      4\u001b[0m                            collate_fn\u001b[38;5;241m=\u001b[39mcollate_batch)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_list, batch_sampler\u001b[38;5;241m=\u001b[39mbatch_sampler(train_list),\n\u001b[1;32m      8\u001b[0m                            collate_fn\u001b[38;5;241m=\u001b[39mcollate_batch)\n",
            "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, device, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, dataloader, device, optimizer, loss_fn):\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      4\u001b[0m         x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/anaconda3/envs/colab/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/envs/colab/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/anaconda3/envs/colab/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mcollate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_batch\u001b[39m(batch):\n\u001b[1;32m      3\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor(y)\n",
            "File \u001b[0;32m~/anaconda3/envs/colab/lib/python3.10/site-packages/torch/nn/utils/rnn.py:378\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    374\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(1, 10):\n",
        "    t1 = time.time()\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_list, batch_sampler=batch_sampler(train_list),\n",
        "                               collate_fn=collate_batch)\n",
        "    train(model, train_dataloader, device, optimizer, loss_fn)\n",
        "    t2 = time.time()\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_list, batch_sampler=batch_sampler(train_list),\n",
        "                               collate_fn=collate_batch)\n",
        "    train_loss, train_accuracy = test(model, train_dataloader, device, loss_fn, metrics_fn)\n",
        "    t3 = time.time()\n",
        "    print('\\nEpoch {}'.format(epoch))\n",
        "    print('Training Loss: {:.4f}, Training Accuracy: {:.2f}%'.format(train_loss, train_accuracy*100))\n",
        "\n",
        "    t4 = time.time()\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_list, batch_sampler=batch_sampler(test_list),\n",
        "                               collate_fn=collate_batch)\n",
        "    test_loss, test_accuracy = test(model, test_dataloader, device, loss_fn, metrics_fn) \n",
        "    t5 = time.time()\n",
        "    print('Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(test_loss, test_accuracy*100))\n",
        "    print('Time elapsed - Training: {:.2f}, test train: {:.2f}, test test: {:.2f}'.format(t2-t1, t3-t2, t5-t4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "186977ea-61d8-4cd5-858e-277aa42a8e60"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}